{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Varvara Yakovleva\n",
    "176984\n",
    "Segment a data set using k-means and train a classification model on each cluster. \n",
    "Compare performance with or without this pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Varvar/Desktop/env1/pythonenv1/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['M', 0.35, 0.265, ..., 0.0485, 0.07, 7],\n",
       "       ['F', 0.53, 0.42, ..., 0.1415, 0.21, 9],\n",
       "       ['M', 0.44, 0.365, ..., 0.114, 0.155, 10],\n",
       "       ..., \n",
       "       ['M', 0.6, 0.475, ..., 0.2875, 0.308, 9],\n",
       "       ['F', 0.625, 0.485, ..., 0.261, 0.29600000000000004, 10],\n",
       "       ['M', 0.71, 0.555, ..., 0.3765, 0.495, 12]], dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/abalone/abalone.data')\n",
    "df = np.asarray(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Varvar/Desktop/env1/pythonenv1/lib/python2.7/site-packages/sklearn/utils/validation.py:444: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "Y = df[:,0]\n",
    "X = df[:, 1:]\n",
    "#scale \n",
    "scaler = preprocessing.StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification model. Decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "future_tree = RandomForestClassifier()\n",
    "future_tree.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[135,  37, 152],\n",
       "       [ 45, 260,  42],\n",
       "       [153,  77, 143]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = future_tree.predict(X_test)\n",
    "confusion_matrix(Y_test,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          F       0.41      0.42      0.41       324\n",
      "          I       0.70      0.75      0.72       347\n",
      "          M       0.42      0.38      0.40       373\n",
      "\n",
      "avg / total       0.51      0.52      0.51      1044\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(Y_test,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.51532567049808431"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_test, prediction)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "No need to separate in train and test before k-means because it is unsupervised learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters = 5, init='k-means++')\n",
    "kmeans.fit(X)\n",
    "prediction_clusters = kmeans.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train a model using the same technique as above for each cluster\n",
    "X=np.column_stack((X,prediction_clusters))\n",
    "\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,train_size=0.75)\n",
    "c_train=X_train[:,-1]\n",
    "c_test=X_test[:,-1]\n",
    "\n",
    "#scale\n",
    "scalerx = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train=scalerx.transform(X_train)\n",
    "X_test=scalerx.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train0,y_train0=X_train[np.where(c_train==0)],Y_train[np.where(c_train==0)]\n",
    "X_train1,y_train1=X_train[np.where(c_train==1)],Y_train[np.where(c_train==1)]\n",
    "X_train2,y_train2=X_train[np.where(c_train==2)],Y_train[np.where(c_train==2)]\n",
    "X_train3,y_train3=X_train[np.where(c_train==3)],Y_train[np.where(c_train==3)]\n",
    "X_train4,y_train4=X_train[np.where(c_train==4)],Y_train[np.where(c_train==4)]\n",
    "\n",
    "X_test0,y_test0=X_test[np.where(c_test==0)],Y_test[np.where(c_test==0)]\n",
    "X_test1,y_test1=X_test[np.where(c_test==1)],Y_test[np.where(c_test==1)]\n",
    "X_test2,y_test2=X_test[np.where(c_test==2)],Y_test[np.where(c_test==2)]\n",
    "X_test3,y_test3=X_test[np.where(c_test==3)],Y_test[np.where(c_test==3)]\n",
    "X_test4,y_test4=X_test[np.where(c_test==4)],Y_test[np.where(c_test==4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_tree = RandomForestClassifier()\n",
    "\n",
    "future_tree.fit(X_train0,y_train0)\n",
    "pred0=future_tree.predict(X_test0)\n",
    "\n",
    "future_tree.fit(X_train1,y_train1)\n",
    "pred1=future_tree.predict(X_test1)\n",
    "\n",
    "future_tree.fit(X_train2,y_train2)\n",
    "pred2=future_tree.predict(X_test2)\n",
    "\n",
    "future_tree.fit(X_train3,y_train3)\n",
    "pred3=future_tree.predict(X_test3)\n",
    "\n",
    "future_tree.fit(X_train4,y_train4)\n",
    "pred4=future_tree.predict(X_test4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test=np.concatenate((y_test0, y_test1,y_test2, y_test3, y_test4), axis=0)\n",
    "prediction=np.concatenate((pred0, pred1, pred2, pred3, pred4), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[162,  42, 136],\n",
       "       [ 43, 232,  41],\n",
       "       [163,  75, 150]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(Y_test,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          F       0.44      0.48      0.46       340\n",
      "          I       0.66      0.73      0.70       316\n",
      "          M       0.46      0.39      0.42       388\n",
      "\n",
      "avg / total       0.52      0.52      0.52      1044\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(Y_test,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.52107279693486586"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
